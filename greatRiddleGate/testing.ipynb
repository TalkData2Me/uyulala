{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/python\n",
    "\n",
    "\n",
    "'''\n",
    "rightSphnix:\n",
    "* create Labels and store to disk\n",
    "* build models\n",
    "'''\n",
    "\n",
    "##################################################################################\n",
    "#########################       Configure       ##################################\n",
    "##################################################################################\n",
    "\n",
    "assets = 'Test'   # Typically AllStocks, SchwabOneSource, SchwabETFs, or Test\n",
    "horizon = 2       # prediction horizon in days\n",
    "\n",
    "totalBuildTimeAllowed_seconds = 28800\n",
    "\n",
    "\n",
    "startDate = '2001-01-01'\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "importing packages\n"
     ]
    }
   ],
   "source": [
    "\n",
    "##################################################################################\n",
    "###########################       Imports       ##################################\n",
    "##################################################################################\n",
    "print('importing packages')\n",
    "from multiprocessing import Pool\n",
    "import pandas\n",
    "import os\n",
    "import uyulala\n",
    "#reload(uyulala)\n",
    "\n",
    "import datetime\n",
    "import numpy\n",
    "import random\n",
    "import string\n",
    "import subprocess\n",
    "import time\n",
    "from psutil import virtual_memory\n",
    "import shutil\n",
    "from pathlib import Path\n",
    "import math\n",
    "import glob\n",
    "import shutil\n",
    "\n",
    "totMem = virtual_memory().total\n",
    "availMem = virtual_memory().available\n",
    "\n",
    "folderName = 'Assets-'+assets+'--Hrzn-'+str(horizon)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "clearing directories\n"
     ]
    }
   ],
   "source": [
    "\n",
    "##################################################################################\n",
    "#################              Clear directories          ########################\n",
    "##################################################################################\n",
    "print('clearing directories')\n",
    "try:\n",
    "    shutil.rmtree(os.path.join(uyulala.dataDir,'labeled',folderName))\n",
    "    os.makedirs(os.path.join(uyulala.dataDir,'labeled',folderName))\n",
    "except:\n",
    "    os.makedirs(os.path.join(uyulala.dataDir,'labeled',folderName))\n",
    "\n",
    "try:\n",
    "    shutil.rmtree(os.path.join(uyulala.modelsDir,folderName))\n",
    "    os.makedirs(os.path.join(uyulala.modelsDir,folderName))\n",
    "except:\n",
    "    os.makedirs(os.path.join(uyulala.modelsDir,folderName))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n##################################################################################\\n################# Get and transform data (run leftSphnix) ########################\\n##################################################################################\\nprint(\\'getting and transforming data\\')\\nif assets!=\"Test\":\\n    import warnings\\n    warnings.filterwarnings(\"ignore\")\\n\\n\\nfilePath = os.path.join(uyulala.uyulalaDir,\\'greatRiddleGate\\',\\'leftSphnix.py\\')\\nprint(\\'making call: \\'+\\'python %s --assets=%s --horizon=%i --start=%s\\' % (filePath,assets,horizon,startDate))\\nsubprocess.call(\\'python %s --assets=%s --horizon=%i --start=%s\\' % (filePath,assets,horizon,startDate), shell=True)\\n\\n'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "##################################################################################\n",
    "################# Get and transform data (run leftSphnix) ########################\n",
    "##################################################################################\n",
    "print('getting and transforming data')\n",
    "if assets!=\"Test\":\n",
    "    import warnings\n",
    "    warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "\n",
    "filePath = os.path.join(uyulala.uyulalaDir,'greatRiddleGate','leftSphnix.py')\n",
    "print('making call: '+'python %s --assets=%s --horizon=%i --start=%s' % (filePath,assets,horizon,startDate))\n",
    "subprocess.call('python %s --assets=%s --horizon=%i --start=%s' % (filePath,assets,horizon,startDate), shell=True)\n",
    "\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "creating \n"
     ]
    }
   ],
   "source": [
    "\n",
    "##################################################################################\n",
    "########################       Create        ###############################\n",
    "##################################################################################\n",
    "print('creating ')\n",
    "\n",
    "evaluate = [ f.replace('.csv','') for f in os.listdir(os.path.join(uyulala.dataDir,'raw',folderName)) if f.endswith(\".csv\") ]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def createLabels(asset=''):\n",
    "    try:\n",
    "        labeled = pandas.read_csv(os.path.join(uyulala.dataDir,'raw',folderName,asset+'.csv'),parse_dates=['DateCol']).set_index('DateCol',drop=False)\n",
    "        labeled = labeled.drop_duplicates(subset=['Date'], keep='last') # KEEP EVERYTHING BELOW THIS POINT IN ORDER\n",
    "        print('label for biggest loss') # Key Regression Field (what's the biggest loss?)\n",
    "        labeled = uyulala.lowPercentChange(df=labeled,horizon=horizon)\n",
    "        print('label for highest gain') # Key Regression Field (what's the predicted return?)\n",
    "        labeled = uyulala.percentChange(df=labeled,horizon=horizon,HighOrClose='High')\n",
    "        print('label for whether higest gain comes before biggest loss') # Key Classification Field (is it a good buy?)\n",
    "        labeled = uyulala.expectedReturnPct(df=labeled,horizon=horizon)\n",
    "        print('add weights column')  #add weights\n",
    "        labeled = uyulala.weights(df=labeled, horizon=horizon,weightForIncrease=1,weightForDecrease=2)\n",
    "        labeled = labeled.drop(['Open','High','Low','Close','Volume'],axis=1)\n",
    "        labeled['YearMo'] = labeled['DateCol'].dt.strftime('%Y%m')\n",
    "        labeled['Asset'] = labeled['Symbol']\n",
    "        labeled.to_parquet(os.path.join(uyulala.dataDir,'labeled',folderName),index=False,partition_cols=['YearMo','Asset'])\n",
    "        return asset\n",
    "    except:\n",
    "        print('unable to create label for '+asset)\n",
    "        pass\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "labelling data\n",
      "label for biggest losslabel for biggest losslabel for biggest loss\n",
      "\n",
      "\n",
      "label for highest gainlabel for highest gainlabel for highest gain\n",
      "\n",
      "\n",
      "label for whether higest gain comes before biggest losslabel for whether higest gain comes before biggest losslabel for whether higest gain comes before biggest loss\n",
      "\n",
      "\n",
      "add weights column\n",
      "add weights column\n",
      "add weights column\n",
      "Done labelling data\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print('labelling data')\n",
    "for i in range(0,len(evaluate),400):\n",
    "    l = evaluate[i:i+400]\n",
    "    pool = Pool(uyulala.availableCores,maxtasksperchild=1)\n",
    "    pool.map(createLabels, l)\n",
    "    pool.close()\n",
    "    pool.join()\n",
    "\n",
    "print('Done labelling data')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#h2o.cluster().shutdown()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking whether there is an H2O instance running at http://localhost:54321 ..... not found.\n",
      "Attempting to start a local H2O server...\n",
      "  Java Version: java version \"1.8.0_101\"; Java(TM) SE Runtime Environment (build 1.8.0_101-b13); Java HotSpot(TM) 64-Bit Server VM (build 25.101-b13, mixed mode)\n",
      "  Starting server from /Users/Damian/opt/anaconda3/envs/uyulala/lib/python3.7/site-packages/h2o/backend/bin/h2o.jar\n",
      "  Ice root: /var/folders/5b/s4769fcn60d842cy18f7nc3h0000gn/T/tmpa3obf7e7\n",
      "  JVM stdout: /var/folders/5b/s4769fcn60d842cy18f7nc3h0000gn/T/tmpa3obf7e7/h2o_Damian_started_from_python.out\n",
      "  JVM stderr: /var/folders/5b/s4769fcn60d842cy18f7nc3h0000gn/T/tmpa3obf7e7/h2o_Damian_started_from_python.err\n",
      "  Server is running at http://127.0.0.1:54321\n",
      "Connecting to H2O server at http://127.0.0.1:54321 ... successful.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td>H2O_cluster_uptime:</td>\n",
       "<td>01 secs</td></tr>\n",
       "<tr><td>H2O_cluster_timezone:</td>\n",
       "<td>America/Chicago</td></tr>\n",
       "<tr><td>H2O_data_parsing_timezone:</td>\n",
       "<td>UTC</td></tr>\n",
       "<tr><td>H2O_cluster_version:</td>\n",
       "<td>3.30.1.3</td></tr>\n",
       "<tr><td>H2O_cluster_version_age:</td>\n",
       "<td>24 days </td></tr>\n",
       "<tr><td>H2O_cluster_name:</td>\n",
       "<td>H2O_from_python_Damian_tn0qwt</td></tr>\n",
       "<tr><td>H2O_cluster_total_nodes:</td>\n",
       "<td>1</td></tr>\n",
       "<tr><td>H2O_cluster_free_memory:</td>\n",
       "<td>6.223 Gb</td></tr>\n",
       "<tr><td>H2O_cluster_total_cores:</td>\n",
       "<td>24</td></tr>\n",
       "<tr><td>H2O_cluster_allowed_cores:</td>\n",
       "<td>24</td></tr>\n",
       "<tr><td>H2O_cluster_status:</td>\n",
       "<td>accepting new members, healthy</td></tr>\n",
       "<tr><td>H2O_connection_url:</td>\n",
       "<td>http://127.0.0.1:54321</td></tr>\n",
       "<tr><td>H2O_connection_proxy:</td>\n",
       "<td>{\"http\": null, \"https\": null}</td></tr>\n",
       "<tr><td>H2O_internal_security:</td>\n",
       "<td>False</td></tr>\n",
       "<tr><td>H2O_API_Extensions:</td>\n",
       "<td>Amazon S3, XGBoost, Algos, AutoML, Core V3, TargetEncoder, Core V4</td></tr>\n",
       "<tr><td>Python_version:</td>\n",
       "<td>3.7.6 final</td></tr></table></div>"
      ],
      "text/plain": [
       "--------------------------  ------------------------------------------------------------------\n",
       "H2O_cluster_uptime:         01 secs\n",
       "H2O_cluster_timezone:       America/Chicago\n",
       "H2O_data_parsing_timezone:  UTC\n",
       "H2O_cluster_version:        3.30.1.3\n",
       "H2O_cluster_version_age:    24 days\n",
       "H2O_cluster_name:           H2O_from_python_Damian_tn0qwt\n",
       "H2O_cluster_total_nodes:    1\n",
       "H2O_cluster_free_memory:    6.223 Gb\n",
       "H2O_cluster_total_cores:    24\n",
       "H2O_cluster_allowed_cores:  24\n",
       "H2O_cluster_status:         accepting new members, healthy\n",
       "H2O_connection_url:         http://127.0.0.1:54321\n",
       "H2O_connection_proxy:       {\"http\": null, \"https\": null}\n",
       "H2O_internal_security:      False\n",
       "H2O_API_Extensions:         Amazon S3, XGBoost, Algos, AutoML, Core V3, TargetEncoder, Core V4\n",
       "Python_version:             3.7.6 final\n",
       "--------------------------  ------------------------------------------------------------------"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "importing data\n"
     ]
    }
   ],
   "source": [
    "\n",
    "##################################################################################\n",
    "##########################       Load Data       #################################\n",
    "##################################################################################\n",
    "\n",
    "\n",
    "import h2o\n",
    "from h2o.automl import H2OAutoML\n",
    "from h2o.estimators.gbm import H2OGradientBoostingEstimator\n",
    "from h2o.grid.grid_search import H2OGridSearch\n",
    "from h2o.frame import H2OFrame\n",
    "\n",
    "try:\n",
    "    h2o.init(nthreads = -1,max_mem_size=\"%sG\" % int(totMem/1500000000/1.5),min_mem_size=\"%sG\" % int(availMem/1500000000/1.5))\n",
    "except:\n",
    "    time.sleep(20)\n",
    "    h2o.init(nthreads = -1,max_mem_size=\"%sG\" % int(totMem/1500000000/1.5),min_mem_size=\"%sG\" % int(availMem/1500000000/1.5))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "full data size: 0.017388292gb\n"
     ]
    }
   ],
   "source": [
    "dataSize = sum(f.stat().st_size for f in Path(os.path.join(uyulala.dataDir,'transformed',folderName)).glob('**/*') if f.is_file() ) + sum(f.stat().st_size for f in Path(os.path.join(uyulala.dataDir,'labeled',folderName)).glob('**/*') if f.is_file() )\n",
    "ratio = ((availMem/2000000000) / (20.0000000000000)) / (dataSize/1000000000)\n",
    "print('full data size: {}gb'.format(dataSize/1000000000.00))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "YrMos = [str(f)[-6:] for f in Path(os.path.join(uyulala.dataDir,'labeled',folderName)).glob('**/*') if f.is_dir()]\n",
    "YrMos = [f for f in YrMos if f.startswith('20') | f.startswith('19')]\n",
    "ootMonths = YrMos[-int(len(YrMos)*0.1):] #use latest 10% of months as holdout set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n1,2,3,4,5\\n6,7,8,9,10\\n11,12,1,2,3\\n4,5,6,7,8\\n9,10,11,12,1\\n\\n2,3,4,5,6\\n7,8,9,10,11\\n12,1,2,3,4\\n5,6,7,8,9\\n10,11,12,1,2\\n\\n3,4,5,6,7\\n8,9,10,11,12\\n'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "1,2,3,4,5\n",
    "6,7,8,9,10\n",
    "11,12,1,2,3\n",
    "4,5,6,7,8\n",
    "9,10,11,12,1\n",
    "\n",
    "2,3,4,5,6\n",
    "7,8,9,10,11\n",
    "12,1,2,3,4\n",
    "5,6,7,8,9\n",
    "10,11,12,1,2\n",
    "\n",
    "3,4,5,6,7\n",
    "8,9,10,11,12\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### HYPERPARAMETER TUNING AND VARIABLE SELECTION\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
